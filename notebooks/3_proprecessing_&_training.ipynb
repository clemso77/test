{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffda28ba",
   "metadata": {},
   "source": [
    "# Preprocessing and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4321036",
   "metadata": {},
   "source": [
    "In this report, we will go over how we approached the preprocessing of our data and the training of our models.\n",
    "\n",
    "**IMPORTANT :** We will not execute python code in this report. The training and preprocessing are done within the python files found in the `scripts` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378c041",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### What are we preprocessing for\n",
    "\n",
    "Before starting the preprocessing of our dataset, we need to go over what we are preprocessing for. And we have 2 different cases with 3 subcases each.\n",
    "\n",
    "The first case is when we are training for classical models (linear regression, random forest, grandient boosting, ...) and the second one is when we are preprocessing for Generalized Additive Models (GAMs).\n",
    "\n",
    "In each one of these cases, we will also want to process our data for the 3 following cases :\n",
    "1. All year\n",
    "2. Only winter data\n",
    "3. Only summer data\n",
    "The goal is to see if models based on only data from one season will outperform a model regrouping these two seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c5d72",
   "metadata": {},
   "source": [
    "### Preprocessing for classical models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31712d",
   "metadata": {},
   "source": [
    "#### Classical models\n",
    "\n",
    "**Script :** data_proprocessing.py\n",
    "\n",
    "First of all, we will list you the different feature transformation we did for the classical models :\n",
    "\n",
    "* `LOCAL_TIME` was split into 2 new features : `LOCAL_TIME_HOUR` and `LOCAL_TIME_MINUTE`\n",
    "* `WEEK_DAY` was converted from a string to a number (Monday = 0, Tuesday = 1, ..., Sunday = 6)\n",
    "* `ROUTE` was used to filter out the data with no real toue associated with it\n",
    "* A `SEASON` variable was created with summer being the months of May through September and Winter being the rest\n",
    "* `PRECIP_AMOUNT` was turned into a binary variable (either there are precipitations or there are none)\n",
    "* `VISIBILITY` was turned into an ordinal categorical variable : \n",
    "\n",
    "    * Great visibility (16 km <= visibility)\n",
    "    * Correct visibility (12 km <= visibility < 16 km)\n",
    "    * Poor visibility (8 km <= visibility < 12 km)\n",
    "    * Very poor wisibility (4 km <= visibility < 8 km)\n",
    "    * No visibility (visibility < 4 km)\n",
    "\n",
    "* `WEATHER_ENG_DESC` had its values regrouped into 3 broader categories (a single incident can belong to multiple categories) : \n",
    "\n",
    "    * Rain (Moderate Rain, Freezing Rain, Heavy Rain)\n",
    "    * Fog (Freezing Fog, Haze)\n",
    "    * Snow (Moderate Snow)\n",
    "\n",
    "* `INCIDENT` had its value regrouped into 5 broader catergories :\n",
    "\n",
    "    * Safety (Collision - TTC, Security, Emergency Services, Investigation)\n",
    "    * Operational (Operations - Operator, Held By, Utilized Off Route)\n",
    "    * Technical (Mechanical, Cleaning - Unsanitary)\n",
    "    * External (Road Blocked - NON-TTC Collision, Diversion)\n",
    "    * Other (General Delay, Vision)\n",
    "\n",
    "Here are the different processings we did for each feature :\n",
    "\n",
    "* Cyclical encoding : `LOCAL_TIME_HOUR`, `LOCAL_TIME_HOUR`, `WEEK_DAY`, `LOCAL_MONTH`, `LOCAL_DAY`, `WIND_DIRECTION`\n",
    "* Yeo-Johnson transformation : `WIND_SPEED`\n",
    "* Standard scaling : `TEMP`, `DEW_POINT_TEMP`, `HUMIDEX`, `RELATIVE_HUMIDITY`, `STATION_PRESSURE`, `WIND_SPEED`\n",
    "* Onehot encoding : `ROUTE`, `INCIDENT`, `SEASON`\n",
    "* Ordinal encoding : `VISIBILITY` with the following order :\n",
    "\n",
    "    * No visibility, Very poor visibility, Poor visibility, Correct visibility, Great visibility\n",
    "\n",
    "* Multi label binarizing : `WEATHER_ENG_DESC_LIST` \n",
    "\n",
    "After these treatments, we delete all NaN values.\n",
    "\n",
    "**Result file :** 4_preprocessed_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04583647",
   "metadata": {},
   "source": [
    "#### GAM models \n",
    "\n",
    "**Script :** data_preprocessing_pygam.py\n",
    "\n",
    "First of all, we will list you the different feature transformation we did for the GAMs :\n",
    "\n",
    "* `LOCAL_TIME` was split into 2 new features : `LOCAL_TIME_HOUR` and `LOCAL_TIME_MINUTE`\n",
    "* `WEEK_DAY` was converted from a string to a number (Monday = 0, Tuesday = 1, ..., Sunday = 6)\n",
    "* `ROUTE` was used to filter out the data with no real toue associated with it\n",
    "* A `SEASON` variable was created with summer being the months of May through September and Winter being the rest\n",
    "* `PRECIP_AMOUNT` was turned into a binary variable (either there are precipitations or there are none)\n",
    "* `VISIBILITY` was turned into an ordinal categorical variable : \n",
    "\n",
    "    * Great visibility (16 km <= visibility)\n",
    "    * Correct visibility (12 km <= visibility < 16 km)\n",
    "    * Poor visibility (8 km <= visibility < 12 km)\n",
    "    * Very poor wisibility (4 km <= visibility < 8 km)\n",
    "    * No visibility (visibility < 4 km)\n",
    "\n",
    "* `WEATHER_ENG_DESC` had its values regrouped into 3 broader categories (a single incident can belong to multiple categories) : \n",
    "\n",
    "    * Rain (Moderate Rain, Freezing Rain, Heavy Rain)\n",
    "    * Fog (Freezing Fog, Haze)\n",
    "    * Snow (Moderate Snow)\n",
    "\n",
    "* `INCIDENT` had its value regrouped into 5 broader catergories :\n",
    "\n",
    "    * Safety (Collision - TTC, Security, Emergency Services, Investigation)\n",
    "    * Operational (Operations - Operator, Held By, Utilized Off Route)\n",
    "    * Technical (Mechanical, Cleaning - Unsanitary)\n",
    "    * External (Road Blocked - NON-TTC Collision, Diversion)\n",
    "    * Other (General Delay, Vision)\n",
    "\n",
    "Before preprocessing the data, we clipped the data to its 1st and 99th percentile on numerical columns to limit outliers:\n",
    "\n",
    "```python\n",
    "for col in numerical_columns:\n",
    "    lower_bound = df[col].quantile(0.01)\n",
    "    upper_bound = df[col].quantile(0.99)\n",
    "    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "```\n",
    "\n",
    "Here are the different processings we did for each feature :\n",
    "\n",
    "* Cyclical encoding : `LOCAL_TIME_HOUR`, `LOCAL_TIME_HOUR`, `WEEK_DAY`, `LOCAL_MONTH`, `LOCAL_DAY`, `WIND_DIRECTION`\n",
    "* Ordinal encoding : `ROUTE`, `INCIDENT`, `SEASON`, `VISIBILITY` with the following order :\n",
    "\n",
    "    * Unkown order for `ROUTE`, `INCIDENT`, `SEASON`\n",
    "    * No visibility, Very poor visibility, Poor visibility, Correct visibility, Great visibility\n",
    "\n",
    "* Multi label binarizing : `WEATHER_ENG_DESC_LIST` \n",
    "\n",
    "After these treatments, we delete all NaN values.\n",
    "\n",
    "The main difference with classical models is that we do not use one hot encoding or scale our variables since GAMs do not require such treatments.\n",
    "\n",
    "**Result file :** 4_preprocessed_dataset_pygam.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2153c256",
   "metadata": {},
   "source": [
    "#### Season splitting \n",
    "\n",
    "**Scripts :** \n",
    "\n",
    "* data_preprocessing_only_summer.py\n",
    "* data_preprocessing_only_winter.py\n",
    "* data_preprocessinfg_pygam_summer.py\n",
    "* data_preprocessinfg_pygam_winter.py\n",
    "\n",
    "To split the season, we just looked up the season variable and deleted the rows not meeting the season criteria we are looking for. We also removed the season variable from the data after this treatment.\n",
    "\n",
    "The operation is the same in both classical and GAM preprocessing\n",
    "\n",
    "**Result files :**\n",
    "\n",
    "* 4_preprocessed_dataset_summer.py\n",
    "* 4_preprocessed_dataset_winter.py\n",
    "* 4_preprocessed_dataset_pygam_summer.py\n",
    "* 4_preprocessed_dataset_pygam_winter.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd6d52",
   "metadata": {},
   "source": [
    "## Model training and evaluation\n",
    "\n",
    "### How did we train\n",
    "\n",
    "To train our data, we decided to go for a train, test, validation split. The proportion of the data put in each category will be specified for each different test scenario we did. We use the train data to train models, the test data to hyperoptimize the model and the validation data to finally test our hyperoptimized model.\n",
    "\n",
    "We also used optuna to hyperoptimize our models. We hyperoptimized on 100 trials per model (except if we explicitly say that we didn't). This hyperoptimization is trying to minimize the root mean squared error (rmse). We chose this metric because, through testing, we established that it was the metric that gave us the best results while hyperoptimizing the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d340f8",
   "metadata": {},
   "source": [
    "#### Scenario 1 - Classical models, All seasons\n",
    "\n",
    "* **Entry data :** 4_preprocessed_dataset.csv\n",
    "* **Script :** train_models.py\n",
    "* **Train/Test/Validation split :** Train (60%)/Validation (20%)/Test (20%) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0698c947",
   "metadata": {},
   "source": [
    "##### Decision Tree\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"criterion\": trial.suggest_categorical(\"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"]),\n",
    "    \"splitter\": trial.suggest_categorical(\"splitter\", [\"best\", \"random\"]),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 1, 50),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 1000),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1),\n",
    "}\n",
    "```\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"splitter\": \"random\",\n",
    "    \"max_depth\": 31,\n",
    "    \"min_samples_split\": 6,\n",
    "    \"min_samples_leaf\": 11,\n",
    "    \"min_weight_fraction_leaf\": 0.00014557343303502968,\n",
    "    \"max_features\": None,\n",
    "    \"max_leaf_nodes\": 861,\n",
    "    \"min_impurity_decrease\": 0.004493554362112649\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2289\n",
    "* **MAE :** 0.5594\n",
    "* **RMSE :** 0.7146\n",
    "\n",
    "![Decision Tree Results - Scenario 1](./1/Decision%20Tree-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d46e7",
   "metadata": {},
   "source": [
    "##### Linear Regression (classical)\n",
    "\n",
    "Since only 4 cases are possible, only 4 trials are ran.\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"copy_X\": True, \n",
    "    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "    \"positive\": trial.suggest_categorical(\"positive\", [True, False]),\n",
    "}\n",
    "```\n",
    "**Results :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"positive\": True\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2921 \n",
    "* **MAE :** 0.4898\n",
    "* **RMSE :** 0.6560 \n",
    "\n",
    "![Linear Regression (classical) - Scenario 1](1/Linear%20Regression%20(classical)-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f532cea",
   "metadata": {},
   "source": [
    "##### Linear Regression (Elasticnet)\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 10.0, log=True),\n",
    "    \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 500, 5000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2, log=True),\n",
    "    \"selection\": trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"])\n",
    "}\n",
    "```\n",
    "**Results :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"alpha\": 5.68224695093307e-05,\n",
    "    \"l1_ratio\": 0.5124624176875617,\n",
    "    \"fit_intercept\": False,\n",
    "    \"max_iter\": 1891,\n",
    "    \"tol\": 0.0027704838849413305,\n",
    "    \"selection\": \"cyclic\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2948 \n",
    "* **MAE :** 0.4902 \n",
    "* **RMSE :** 0.6535\n",
    "\n",
    "![Linear Regression (elasticnet) - Scenario 1](1/Linear%20Regression%20(Elasticnet)-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e2d77",
   "metadata": {},
   "source": [
    "##### Random Forest\n",
    "\n",
    "We did not execute 100 trials due to extremely long execution times. We executed only 10 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 600),\n",
    "    \"criterion\": trial.suggest_categorical(\n",
    "        \"criterion\", [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "    ),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 40),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\n",
    "        \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "    ),\n",
    "    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 5000),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    \"oob_score\": trial.suggest_categorical(\"oob_score\", [False, True]),\n",
    "    \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1)\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": 149,\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"max_depth\": 23,\n",
    "    \"min_samples_split\": 8,\n",
    "    \"min_samples_leaf\": 20,\n",
    "    \"min_weight_fraction_leaf\": 0.007770028157936426,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"max_leaf_nodes\": 798,\n",
    "    \"min_impurity_decrease\": 0.7201417309527923,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": True,\n",
    "    \"ccp_alpha\": 0.06497372551826268\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.0140\n",
    "* **MAE :** 0.6220\n",
    "* **RMSE :** 0.9137\n",
    "\n",
    "![Random Forest - Scenario 1](1/Random%20Forest-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385f7f5f",
   "metadata": {},
   "source": [
    "##### Gradient Boosting\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"loss\": trial.suggest_categorical(\n",
    "        \"loss\", [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"]\n",
    "    ),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3, log=True),\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 800),\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    \"criterion\": trial.suggest_categorical(\n",
    "        \"criterion\", [\"friedman_mse\", \"squared_error\"]\n",
    "    ),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.3),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "    \"max_features\": trial.suggest_categorical(\n",
    "        \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "    ),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"alpha\": trial.suggest_float(\"alpha\", 0.01, 0.99),  # used for quantile/huber losses\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"loss\": \"huber\",\n",
    "    \"learning_rate\": 0.03471075642674359,\n",
    "    \"n_estimators\": 540,\n",
    "    \"subsample\": 0.8855618217015933,\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"min_samples_split\": 15,\n",
    "    \"min_samples_leaf\": 10,\n",
    "    \"min_weight_fraction_leaf\": 0.00011386163288458159,\n",
    "    \"max_depth\": 9,\n",
    "    \"max_features\": None,\n",
    "    \"min_impurity_decrease\": 0.6129026132279136,\n",
    "    \"alpha\": 0.8665875204701363\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.3002 \n",
    "* **MAE :** 0.4465 \n",
    "* **RMSE :** 0.6485\n",
    "\n",
    "![Gradient Boosting - Scenario 1](1/Gradient%20Boosting-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598cfd5",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True),\n",
    "    # Tree parameters\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 12),\n",
    "    \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 10.0, log=True),\n",
    "    \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "    \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 10),\n",
    "    # Regularization\n",
    "    \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "    \"reg_beta\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "    # Subsampling\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "    \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "    \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n",
    "    # Booster & misc.\n",
    "    \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"random_state\": 99,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": 1176,\n",
    "    \"learning_rate\": 0.018310088659669047,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_child_weight\": 0.2433298670322095,\n",
    "    \"gamma\": 1.081134221399496,\n",
    "    \"max_delta_step\": 3,\n",
    "    \"reg_alpha\": 7.084876626164422e-05,\n",
    "    \"reg_lambda\": 9.599288655044234,\n",
    "    \"subsample\": 0.6606285902180087,\n",
    "    \"colsample_bytree\": 0.604577745827854,\n",
    "    \"colsample_bylevel\": 0.9379922099663431,\n",
    "    \"colsample_bynode\": 0.540463702894869,\n",
    "    \"booster\": \"gbtree\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.3296\n",
    "* **MAE :** 0.4746\n",
    "* **RMSE :** 0.6212\n",
    "\n",
    "![XGB - Scenario 1](1/XGBoost-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecac12",
   "metadata": {},
   "source": [
    "##### Support Vector Regression (SVR)\n",
    "\n",
    "We did not execute 100 trials due to extremely long execution times. We executed only 5 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"poly\", \"sigmoid\", \"linear\"])\n",
    "params = {\n",
    "    \"kernel\": kernel,\n",
    "    \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "    \"epsilon\": trial.suggest_float(\"epsilon\", 1e-4, 1.0, log=True),\n",
    "    \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "    \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "}\n",
    "# Kernel-specific parameters\n",
    "if kernel == \"poly\":\n",
    "    params[\"degree\"] = trial.suggest_int(\"degree\", 2, 5)\n",
    "    params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "elif kernel == \"sigmoid\":\n",
    "    params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "```\n",
    "\n",
    "**Results :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"C\": 0.9172634807099763,\n",
    "    \"epsilon\": 0.022277307122931626,\n",
    "    \"shrinking\": False,\n",
    "    \"gamma\": \"scale\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2601\n",
    "* **MAE :** 0.4451\n",
    "* **RMSE :** 0.6857\n",
    "\n",
    "![SVR - Scenario 1](1/SVR-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03221f",
   "metadata": {},
   "source": [
    "#### Scenario 2 - Classical models, Winter\n",
    "\n",
    "* **Entry data :** 4_preprocessed_dataset_winter.csv\n",
    "* **Script :** train_models_winter.py\n",
    "* **Train/Test/Validation split :** Train (60%)/Validation (20%)/Test (20%) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0dde7",
   "metadata": {},
   "source": [
    "##### Decision Tree\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"criterion\": trial.suggest_categorical(\"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"]),\n",
    "    \"splitter\": trial.suggest_categorical(\"splitter\", [\"best\", \"random\"]),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 1, 50),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 1000),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1),\n",
    "}\n",
    "```\n",
    "**Results :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"splitter\": \"random\",\n",
    "    \"max_depth\": 40,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 15,\n",
    "    \"min_weight_fraction_leaf\": 0.0003194808485743293,\n",
    "    \"max_features\": None,\n",
    "    \"max_leaf_nodes\": 886,\n",
    "    \"min_impurity_decrease\": 0.4983751874061905,\n",
    "    \"ccp_alpha\": 0.0062804080152011445\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.1957\n",
    "* **MAE :** 0.5746\n",
    "* **RMSE :** 0.7482\n",
    "\n",
    "![Decision Tree - Scenario 2](2/Decision%20Tree-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbaca8",
   "metadata": {},
   "source": [
    "##### Linear Regression (classical)\n",
    "\n",
    "Since only 4 cases are possible, only 4 trials are ran.\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"copy_X\": True, \n",
    "    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "    \"positive\": trial.suggest_categorical(\"positive\", [True, False]),\n",
    "}\n",
    "```\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"positive\": True\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2853 \n",
    "* **MAE :** 0.5017\n",
    "* **RMSE :** 0.6648\n",
    "\n",
    "![Linear Regression (classical) - Scenario 2](2/Linear%20Regression%20(classical)-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f33a8",
   "metadata": {},
   "source": [
    "##### Linear Regression (Elasticnet)\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 10.0, log=True),\n",
    "    \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 500, 5000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2, log=True),\n",
    "    \"selection\": trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"])\n",
    "}\n",
    "```\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"alpha\": 0.00038542540083133113,\n",
    "    \"l1_ratio\": 0.11733064861417629,\n",
    "    \"fit_intercept\": True,\n",
    "    \"max_iter\": 1227,\n",
    "    \"tol\": 3.074079260630123e-05,\n",
    "    \"selection\": \"random\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2877 \n",
    "* **MAE :** 0.5043 \n",
    "* **RMSE :** 0.6626\n",
    "\n",
    "![Linear Regression (Elasticnet) - Scenario 2](2/Linear%20Regression%20(Elasticnet)-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9a6784",
   "metadata": {},
   "source": [
    "##### Random Forest\n",
    "\n",
    "We did not execute 100 trials due to extremely long execution times. We executed only 1 test with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 600),\n",
    "    \"criterion\": trial.suggest_categorical(\n",
    "        \"criterion\", [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "    ),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 40),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\n",
    "        \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "    ),\n",
    "    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 5000),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    \"oob_score\": trial.suggest_categorical(\"oob_score\", [False, True]),\n",
    "    \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1)\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": 95,\n",
    "    \"criterion\": \"absolute_error\",\n",
    "    \"max_depth\": 25,\n",
    "    \"min_samples_split\": 12,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"min_weight_fraction_leaf\": 0.45092598137957596,\n",
    "    \"max_features\": None,\n",
    "    \"max_leaf_nodes\": 1589,\n",
    "    \"min_impurity_decrease\": 0.16578563594061557,\n",
    "    \"bootstrap\": False,\n",
    "    \"oob_score\": False,\n",
    "    \"ccp_alpha\": 0.02901108238619291\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** -0.0009\n",
    "* **MAE :** 0.6217\n",
    "* **RMSE :** 0.9310\n",
    "\n",
    "![Random Forest - Scenario 2](2/Random%20Forest-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04069f8",
   "metadata": {},
   "source": [
    "##### Gradient Boosting\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"loss\": trial.suggest_categorical(\n",
    "        \"loss\", [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"]\n",
    "    ),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3, log=True),\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 800),\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    \"criterion\": trial.suggest_categorical(\n",
    "        \"criterion\", [\"friedman_mse\", \"squared_error\"]\n",
    "    ),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.3),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "    \"max_features\": trial.suggest_categorical(\n",
    "        \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "    ),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"alpha\": trial.suggest_float(\"alpha\", 0.01, 0.99),  # used for quantile/huber losses\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"loss\": \"absolute_error\"\n",
    "    \"learning_rate\": 0.02280176533792217\n",
    "    \"n_estimators\": 719\n",
    "    \"subsample\": 0.7972495351158401\n",
    "    \"criterion\": \"friedman_mse\"\n",
    "    \"min_samples_split\": 20\n",
    "    \"min_samples_leaf\": 3\n",
    "    \"min_weight_fraction_leaf\": 0.0002052743467058696\n",
    "    \"max_depth\": 9\n",
    "    \"max_features\": \"sqrt\"\n",
    "    \"min_impurity_decrease\": 0.20369418638457593\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2625 \n",
    "* **MAE :** 0.4650 \n",
    "* **RMSE :** 0.6860\n",
    "\n",
    "![Gradient Boosting - Scenario 2](2/Gradient%20Boosting-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4820b5a",
   "metadata": {},
   "source": [
    "##### Extreme Gradient Boosting\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True),\n",
    "    # Tree parameters\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 12),\n",
    "    \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 10.0, log=True),\n",
    "    \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "    \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 10),\n",
    "    # Regularization\n",
    "    \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "    \"reg_beta\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "    # Subsampling\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "    \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "    \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n",
    "    # Booster & misc.\n",
    "    \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"random_state\": 99,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": 806\n",
    "    \"learning_rate\": 0.03029302502803171\n",
    "    \"max_depth\": 8\n",
    "    \"min_child_weight\": 0.0038121797269087977\n",
    "    \"gamma\": 0.965193111361264\n",
    "    \"max_delta_step\": 7\n",
    "    \"reg_alpha\": 0.0034736346194687985\n",
    "    \"reg_lambda\": 6.023943153925873\n",
    "    \"subsample\": 0.7307550264958214\n",
    "    \"colsample_bytree\": 0.5900537660484718\n",
    "    \"colsample_bylevel\": 0.5196737746952808\n",
    "    \"colsample_bynode\": 0.6219074422247004\n",
    "    \"booster\": \"gbtree\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.3182\n",
    "* **MAE :** 0.4916\n",
    "* **RMSE :** 0.6342\n",
    "\n",
    "![XGB - Scenario 2](2/XGBoost-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327d8b6",
   "metadata": {},
   "source": [
    "### Support Vector Regression (SVR)\n",
    "\n",
    "We did not execute 100 trials due to extremely long execution times. We executed only 5 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"poly\", \"sigmoid\", \"linear\"])\n",
    "params = {\n",
    "    \"kernel\": kernel,\n",
    "    \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "    \"epsilon\": trial.suggest_float(\"epsilon\", 1e-4, 1.0, log=True),\n",
    "    \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "    \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "}\n",
    "# Kernel-specific parameters\n",
    "if kernel == \"poly\":\n",
    "    params[\"degree\"] = trial.suggest_int(\"degree\", 2, 5)\n",
    "    params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "elif kernel == \"sigmoid\":\n",
    "    params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"kernel\": \"poly\"\n",
    "    \"C\": 4.944955595207548\n",
    "    \"epsilon\": 0.02175537301173423\n",
    "    \"shrinking\": True\n",
    "    \"gamma\": \"scale\"\n",
    "    \"degree\": 2\n",
    "    \"coef0\": 0.4962961764689876\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2570\n",
    "* **MAE :** 0.4472\n",
    "* **RMSE :** 0.6911\n",
    "\n",
    "![SVR - Scenario 2](2/SVR-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04691ced",
   "metadata": {},
   "source": [
    "#### Scenario 3 - Classical models, Summer\n",
    "\n",
    "* **Entry data :** 4_preprocessed_dataset_summer.csv\n",
    "* **Script :** train_models_summer.py\n",
    "* **Train/Test/Validation split :** Train (60%)/Validation (20%)/Test (20%) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c25d4",
   "metadata": {},
   "source": [
    "##### Decision Tree\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"criterion\": trial.suggest_categorical(\"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"]),\n",
    "    \"splitter\": trial.suggest_categorical(\"splitter\", [\"best\", \"random\"]),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 1, 50),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\"max_features\", [None, \"sqrt\", \"log2\"]),\n",
    "    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 2, 1000),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1),\n",
    "}\n",
    "```\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"criterion\": \"friedman_mse\"\n",
    "    \"splitter\": \"best\"\n",
    "    \"max_depth\": 4\n",
    "    \"min_samples_split\": 4\n",
    "    \"min_samples_leaf\": 5\n",
    "    \"min_weight_fraction_leaf\": 0.06298245386908075\n",
    "    \"max_features\": None\n",
    "    \"max_leaf_nodes\": 870\n",
    "    \"min_impurity_decrease\": 0.3937352951676524\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.1615\n",
    "* **MAE :** 0.5799\n",
    "* **RMSE :** 0.7578\n",
    "\n",
    "![Decision Tree - Scenario 3](3/Decision%20Tree-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abed7b",
   "metadata": {},
   "source": [
    "##### Linear Regression (classical)\n",
    "\n",
    "Since only 4 cases are possible, only 4 trials are ran.\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"copy_X\": True, \n",
    "    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "    \"positive\": trial.suggest_categorical(\"positive\", [True, False]),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"fit_intercept\": False,\n",
    "    \"positive\": True\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2826\n",
    "* **MAE :** 0.4824\n",
    "* **RMSE :** 0.6484 \n",
    "\n",
    "![Linear Regression (classical) - Scenario 3](3/Linear%20Regression%20(classical)-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57364d8",
   "metadata": {},
   "source": [
    "##### Linear Regression (Elasticnet)\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"alpha\": trial.suggest_float(\"alpha\", 1e-6, 10.0, log=True),\n",
    "    \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "    \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 500, 5000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2, log=True),\n",
    "    \"selection\": trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"])\n",
    "}\n",
    "```\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"alpha\": 0.0005415904606672672,\n",
    "    \"l1_ratio\": 0.06711143766800608,\n",
    "    \"fit_intercept\": True,\n",
    "    \"max_iter\": 1031,\n",
    "    \"tol\": 0.0025125336203729955,\n",
    "    \"selection\": \"cyclic\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2865 \n",
    "* **MAE :** 0.4874\n",
    "* **RMSE :** 0.6449 \n",
    "\n",
    "![Linear Regression (Elasticnet) - Scenario 3](3/Linear%20Regression%20(Elasticnet)-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412dbc9",
   "metadata": {},
   "source": [
    "##### Random Forest\n",
    "\n",
    "We did not execute 100 trials due to extremely long execution times. We executed only 5 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 600),\n",
    "    \"criterion\": trial.suggest_categorical(\n",
    "        \"criterion\", [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "    ),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 40),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5),\n",
    "    \"max_features\": trial.suggest_categorical(\n",
    "        \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "    ),\n",
    "    \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 100, 5000),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "    \"oob_score\": trial.suggest_categorical(\"oob_score\", [False, True]),\n",
    "    \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 0.1)\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": 339,\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"max_depth\": 7,\n",
    "    \"min_samples_split\": 9,\n",
    "    \"min_samples_leaf\": 17,\n",
    "    \"min_weight_fraction_leaf\": 0.4678768997063537,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"max_leaf_nodes\": 952,\n",
    "    \"min_impurity_decrease\": 0.3854587350914097,\n",
    "    \"bootstrap\": False,\n",
    "    \"oob_score\": False,\n",
    "    \"ccp_alpha\": 0.0862227243102725\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** -0.0002\n",
    "* **MAE :** 0.6112\n",
    "* **RMSE :** 0.9040\n",
    "\n",
    "![Random Forest - Scenario 3](3/Random%20Forest-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02d7d4",
   "metadata": {},
   "source": [
    "##### Gradient Boosting\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"loss\": trial.suggest_categorical(\n",
    "        \"loss\", [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"]\n",
    "    ),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.3, log=True),\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 800),\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    \"criterion\": trial.suggest_categorical(\n",
    "        \"criterion\", [\"friedman_mse\", \"squared_error\"]\n",
    "    ),\n",
    "    \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "    \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "    \"min_weight_fraction_leaf\": trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.3),\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "    \"max_features\": trial.suggest_categorical(\n",
    "        \"max_features\", [\"sqrt\", \"log2\", None]\n",
    "    ),\n",
    "    \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 0.0, 1.0),\n",
    "    \"alpha\": trial.suggest_float(\"alpha\", 0.01, 0.99),  # used for quantile/huber losses\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"loss\": \"squared_error\",\n",
    "    \"learning_rate\": 0.08493400397168298,\n",
    "    \"n_estimators\": 355,\n",
    "    \"subsample\": 0.5097553445692088,\n",
    "    \"criterion\": \"friedman_mse\",\n",
    "    \"min_samples_split\": 4,\n",
    "    \"min_samples_leaf\": 18,\n",
    "    \"min_weight_fraction_leaf\": 0.0014236179282328368,\n",
    "    \"max_depth\": 4,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"min_impurity_decrease\": 0.8791889749525543,\n",
    "    \"alpha\": 0.5602793761231738\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2969 \n",
    "* **MAE :** 0.4882 \n",
    "* **RMSE :** 0.6354\n",
    "\n",
    "![Gradient Boosting - Scenario 3](3/Gradient%20Boosting-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2761d8",
   "metadata": {},
   "source": [
    "##### Extreme Gradient Boosting\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1500),\n",
    "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log=True),\n",
    "    # Tree parameters\n",
    "    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 12),\n",
    "    \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1e-3, 10.0, log=True),\n",
    "    \"gamma\": trial.suggest_float(\"gamma\", 0.0, 10.0),\n",
    "    \"max_delta_step\": trial.suggest_int(\"max_delta_step\", 0, 10),\n",
    "    # Regularization\n",
    "    \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "    \"reg_beta\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "    # Subsampling\n",
    "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "    \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "    \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "    \"colsample_bynode\": trial.suggest_float(\"colsample_bynode\", 0.5, 1.0),\n",
    "    # Booster & misc.\n",
    "    \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n",
    "    \"tree_method\": \"auto\",\n",
    "    \"random_state\": 99,\n",
    "    \"n_jobs\": -1,\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_estimators\": 1494,\n",
    "    \"learning_rate\": 0.0170096189751765,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 5.340376980313727,\n",
    "    \"gamma\": 0.5052289826389069,\n",
    "    \"max_delta_step\": 5,\n",
    "    \"reg_alpha\": 0.007644430950964261,\n",
    "    \"reg_lambda\": 9.919662875022942,\n",
    "    \"subsample\": 0.8398912127397786,\n",
    "    \"colsample_bytree\": 0.5588507034087213,\n",
    "    \"colsample_bylevel\": 0.8167534931699498,\n",
    "    \"colsample_bynode\": 0.704605503225567,\n",
    "    \"booster\": \"gbtree\"\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.3245\n",
    "* **MAE :** 0.4712\n",
    "* **RMSE :** 0.6106\n",
    "\n",
    "![XGB - Scenario 3](3/XGBoost-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f75c423",
   "metadata": {},
   "source": [
    "##### Support Vector Regression (SVR)\n",
    "\n",
    "We did not execute 100 trials due to extremely long execution times. We executed only 5 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "kernel = trial.suggest_categorical(\"kernel\", [\"rbf\", \"poly\", \"sigmoid\", \"linear\"])\n",
    "params = {\n",
    "    \"kernel\": kernel,\n",
    "    \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "    \"epsilon\": trial.suggest_float(\"epsilon\", 1e-4, 1.0, log=True),\n",
    "    \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "    \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "}\n",
    "# Kernel-specific parameters\n",
    "if kernel == \"poly\":\n",
    "    params[\"degree\"] = trial.suggest_int(\"degree\", 2, 5)\n",
    "    params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "elif kernel == \"sigmoid\":\n",
    "    params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"kernel\": \"rbf\",\n",
    "    \"C\": 1.0202504419935043,\n",
    "    \"epsilon\": 0.17989837469900855,\n",
    "    \"shrinking\": True,\n",
    "    \"gamma\": \"auto\"\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2053\n",
    "* **MAE :** 0.4885\n",
    "* **RMSE :** 0.7183\n",
    "\n",
    "![SVR - Scenario 3](3/SVR-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73764944",
   "metadata": {},
   "source": [
    "#### Scenario 4 - GAMs, All seasons\n",
    "\n",
    "* **Entry data :** 4_preprocessed_dataset_pygam.csv\n",
    "* **Script :** train_pygam.py\n",
    "* **Train/Test/Validation split :** Train (60%)/Validation (20%)/Test (20%) \n",
    "\n",
    "With the following data specifications : \n",
    "\n",
    "```py\n",
    "generic_cols_transf = (\n",
    "    f(0) +  # ROUTE - nominal\n",
    "    f(1) +  # INCIDENT - nominal\n",
    "    f(2) +  # SEASON - nominal\n",
    "    s(3) +  # VISIBILITY - ordinal\n",
    "    f(4) +  # Clear - binary\n",
    "    f(5) +  # Fog - binary\n",
    "    f(6) +  # Rain - binary\n",
    "    f(7) +  # Snow - binary\n",
    "    f(8) +  # Thunderstorms - binary\n",
    "    s(9, basis=\"cp\", edge_knots=[0, 24]) +  # LOCAL_TIME_HOUR - cyclical\n",
    "    s(10, basis=\"cp\", edge_knots=[0, 60]) +  # LOCAL_TIME_MINUTE - cyclical\n",
    "    s(11, basis=\"cp\", edge_knots=[0, 7]) +  # WEEK_DAY - cyclical\n",
    "    s(12, basis=\"cp\", edge_knots=[1, 12]) +  # LOCAL_MONTH - cyclical\n",
    "    s(13, basis=\"cp\", edge_knots=[1, 31]) +  # LOCAL_DAY - cyclical\n",
    "    s(14, basis=\"cp\", edge_knots=[0, 360]) +  # WIND_DIRECTION - cyclical\n",
    "    f(15) +  # PRECIP_AMOUNT_BINARY - binary\n",
    "    s(16) +  # TEMP - continuous\n",
    "    s(17) +  # DEW_POINT_TEMP - continuous\n",
    "    s(18) +  # HUMIDEX - continuous\n",
    "    s(19) +  # RELATIVE_HUMIDITY - continuous\n",
    "    s(20) +  # STATION_PRESSURE - continuous\n",
    "    s(21)    # WIND_SPEED - continuous\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328c810",
   "metadata": {},
   "source": [
    "##### LinearGAM\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": n_splines,\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 5,\n",
    "    \"lam\": 0.3879848363855412,\n",
    "    \"max_iter\": 949,\n",
    "    \"tol\": 1.040858968295515e-06\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2958\n",
    "* **MAE :** 0.4896\n",
    "* **RMSE :** 0.6526\n",
    "\n",
    "![LinearGAM - Scenario 4](4/LinearGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbeaf7e",
   "metadata": {},
   "source": [
    "##### GammaGAM\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": trial.suggest_int(\"n_splines\", 5, 30),\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 7,\n",
    "    \"lam\": 6.996430731372631,\n",
    "    \"max_iter\": 451,\n",
    "    \"tol\": 2.2074610650990642e-05\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2838\n",
    "* **MAE :** 0.4975\n",
    "* **RMSE :** 0.6637\n",
    "\n",
    "![GammaGAM - Scenario 4](4/GammaGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54fb073",
   "metadata": {},
   "source": [
    "##### PoissonGAM\n",
    "\n",
    "We did not execute 100 trials due to long execution times. We executed only 25 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": trial.suggest_int(\"n_splines\", 5, 30),\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 26,\n",
    "    \"lam\": 1.9491937350065412e-05,\n",
    "    \"max_iter\": 844,\n",
    "    \"tol\": 4.3436155909000126e-06\n",
    "}\n",
    "```\n",
    "\n",
    "*  **R² :** 0.2179\n",
    "* **MAE :** 0.5648\n",
    "* **RMSE :** 0.7248\n",
    "\n",
    "![PoissonGAM - Scenario 4](4/PoissonGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325fd242",
   "metadata": {},
   "source": [
    "#### Scenario 5 - GAMs, Winter\n",
    "\n",
    "* **Entry data :** 4_preprocessed_dataset_pygam_winter.csv\n",
    "* **Script :** train_pygam_winter.py\n",
    "* **Train/Test/Validation split :** Train (80%)/Validation (10%)/Test (10%) \n",
    "\n",
    "With the following data specifications : \n",
    "\n",
    "```py\n",
    "generic_cols_transf = (\n",
    "    f(0) +  # ROUTE - nominal\n",
    "    f(1) +  # INCIDENT - nominal\n",
    "    s(2) +  # VISIBILITY - ordinal\n",
    "    f(3) +  # Clear - binary\n",
    "    f(4) +  # Fog - binary\n",
    "    f(5) +  # Rain - binary\n",
    "    f(6) +  # Snow - binary\n",
    "    f(7) +  # Thunderstorms - binary\n",
    "    s(8, basis=\"cp\", edge_knots=[0, 24]) +  # LOCAL_TIME_HOUR - cyclical\n",
    "    s(9, basis=\"cp\", edge_knots=[0, 60]) +  # LOCAL_TIME_MINUTE - cyclical\n",
    "    s(10, basis=\"cp\", edge_knots=[0, 7]) +  # WEEK_DAY - cyclical\n",
    "    s(11, basis=\"cp\", edge_knots=[1, 12]) +  # LOCAL_MONTH - cyclical\n",
    "    s(12, basis=\"cp\", edge_knots=[1, 31]) +  # LOCAL_DAY - cyclical\n",
    "    s(13, basis=\"cp\", edge_knots=[0, 360]) +  # WIND_DIRECTION - cyclical\n",
    "    f(14) +  # PRECIP_AMOUNT_BINARY - binary\n",
    "    s(15) +  # TEMP - continuous\n",
    "    s(16) +  # DEW_POINT_TEMP - continuous\n",
    "    s(17) +  # HUMIDEX - continuous\n",
    "    s(18) +  # RELATIVE_HUMIDITY - continuous\n",
    "    s(19) +  # STATION_PRESSURE - continuous\n",
    "    s(20)    # WIND_SPEED - continuous\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e4fa3",
   "metadata": {},
   "source": [
    "##### LinearGAM\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": n_splines,\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 5,\n",
    "    \"lam\": 6.400741604996376,\n",
    "    \"max_iter\": 500,\n",
    "    \"tol\": 0.00028849210409862127\n",
    "}\n",
    "```\n",
    "\n",
    "* **R² :** 0.3142 \n",
    "* **MAE :** 0.4947 \n",
    "* **RMSE :** 0.6515 \n",
    "\n",
    "![LinearGAM - Scenario 5](5/LinearGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc895f44",
   "metadata": {},
   "source": [
    "##### GammaGAM\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": trial.suggest_int(\"n_splines\", 5, 30),\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 8,\n",
    "    \"lam\": 4.137967988157594,\n",
    "    \"max_iter\": 291,\n",
    "    \"tol\": 9.0734547318602e-05\n",
    "}\n",
    "```\n",
    "\n",
    "* **R2 :** 0.2781 \n",
    "* **MAE :** 0.4929 \n",
    "* **RMSE :** 0.6372\n",
    "\n",
    "![GammaGAM - Scenario 5](5/GammaGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ce4f4",
   "metadata": {},
   "source": [
    "##### PoissonGAM\n",
    "\n",
    "We did not execute 100 trials due to long execution times. We executed only 25 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": trial.suggest_int(\"n_splines\", 5, 30),\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 22,\n",
    "    \"lam\": 1.4981548572944945,\n",
    "    \"max_iter\": 495,\n",
    "    \"tol\": 3.8603138507428227e-05\n",
    "}\n",
    "```\n",
    "\n",
    "* **R2 :** 0.1899\n",
    "* **MAE :** 0.5833\n",
    "* **RMSE :** 0.7444\n",
    "\n",
    "![PoissonGAM - Scenario 5](5/PoissonGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4cc718",
   "metadata": {},
   "source": [
    "#### Scenario 6 - GAMs, Summer\n",
    "\n",
    "* **Entry data :** 4_preprocessed_dataset_pygam_summer.csv\n",
    "* **Script :** train_pygam_summer.py\n",
    "* **Train/Test/Validation split :** Train (80%)/Validation (10%)/Test (10%) \n",
    "\n",
    "With the following data specifications : \n",
    "\n",
    "```py\n",
    "generic_cols_transf = (\n",
    "    f(0) +  # ROUTE - nominal\n",
    "    f(1) +  # INCIDENT - nominal\n",
    "    s(2) +  # VISIBILITY - ordinal\n",
    "    f(3) +  # Clear - binary\n",
    "    f(4) +  # Fog - binary\n",
    "    f(5) +  # Rain - binary\n",
    "    # f(6) +  No Snow (all the data is False) \n",
    "    f(6) +  # Thunderstorms - binary\n",
    "    s(7, basis=\"cp\", edge_knots=[0, 24]) +  # LOCAL_TIME_HOUR - cyclical\n",
    "    s(8, basis=\"cp\", edge_knots=[0, 60]) +  # LOCAL_TIME_MINUTE - cyclical\n",
    "    s(9, basis=\"cp\", edge_knots=[0, 7]) +  # WEEK_DAY - cyclical\n",
    "    s(10, basis=\"cp\", edge_knots=[1, 12]) +  # LOCAL_MONTH - cyclical\n",
    "    s(11, basis=\"cp\", edge_knots=[1, 31]) +  # LOCAL_DAY - cyclical\n",
    "    s(12, basis=\"cp\", edge_knots=[0, 360]) +  # WIND_DIRECTION - cyclical\n",
    "    f(13) +  # PRECIP_AMOUNT_BINARY - binary\n",
    "    s(14) +  # TEMP - continuous\n",
    "    s(15) +  # DEW_POINT_TEMP - continuous\n",
    "    s(16) +  # HUMIDEX - continuous\n",
    "    s(17) +  # RELATIVE_HUMIDITY - continuous\n",
    "    s(18) +  # STATION_PRESSURE - continuous\n",
    "    s(19)    # WIND_SPEED - continuous\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70025033",
   "metadata": {},
   "source": [
    "##### LinearGAM\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": n_splines,\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 7,\n",
    "    \"lam\": 0.17608365605896287,\n",
    "    \"max_iter\": 362,\n",
    "    \"tol\": 3.204106745231952e-06\n",
    "}\n",
    "```\n",
    "\n",
    "* **R2 :** 0.2742 \n",
    "* **MAE :** 0.4608\n",
    "* **RMSE :** 0.6160\n",
    "\n",
    "![LinearGAM - Scenario 6](6/LinearGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f55c44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d7768d7",
   "metadata": {},
   "source": [
    "##### PoissonGAM\n",
    "\n",
    "We did not execute 100 trials due to long execution times. We executed only 25 tests with the following parameters.\n",
    "\n",
    "**Parameters :**\n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": trial.suggest_int(\"n_splines\", 5, 30),\n",
    "    \"lam\": trial.suggest_float(\"lam\", 1e-6, 1e3, log=True),\n",
    "    \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-3, log=True),\n",
    "}\n",
    "```\n",
    "\n",
    "**Results :** \n",
    "\n",
    "```py\n",
    "params = {\n",
    "    \"n_splines\": 21,\n",
    "    \"lam\": 0.27892287949265293,\n",
    "    \"max_iter\": 765,\n",
    "    \"tol\": 9.912575933470949e-06\n",
    "}\n",
    "```\n",
    "\n",
    "* **R2 :** 0.1784\n",
    "* **MAE :** 0.5582\n",
    "* **RMSE :** 0.7279\n",
    "\n",
    "![PoissonGAM - Scenario 6](6/PoissonGAM-scatterplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5e296",
   "metadata": {},
   "source": [
    "## Results summary\n",
    "\n",
    "To end our testing and evaluations of the different models under different scenarios, here is a table summarizing our results.\n",
    "\n",
    "| R² ; MAE ; RMSE                | All seasons                              | Winter                               | Summer                        |\n",
    "|--------------------------------|------------------------------------------|--------------------------------------|-------------------------------|\n",
    "| Decision Tree                  |   *0.2289*   ;   *0.5594*   ;  *0.7146*  |   0.1957   ;   0.5746   ;   0.7482   |  0.1615 ;  0.5799  ;  0.7578  |\n",
    "| Linear Regression (classical)  |   *0.2921*   ;    0.4898    ;   0.6560   |   0.2853   ;   0.5017   ;   0.6648   |  0.2826 ; *0.4824* ; *0.6484* |\n",
    "| Linear Regression (elasticnet) |   *0.2948*   ;    0.4902    ;   0.6535   |   0.2877   ;   0.5043   ;   0.6626   |  0.2865 ; *0.4874* ; *0.6449* |\n",
    "| Random Forest                  |   *0.0140*   ;    0.6220    ;   0.9137   |  -0.0009   ;   0.6217   ;   0.9310   | -0.0002 ; *0.6112* ; *0.9040* |\n",
    "| Gradient Boosting              |   *0.3002*   ;   *0.4465*   ;   0.6485   |   0.2625   ;   0.4650   ;   0.6860   |  0.2969 ;  0.4882  ; *0.6354* |\n",
    "| Extreme Gradient Boosting      | ***0.3296*** ;    0.4746    ; **0.6212** | **0.3182** ;   0.4916   ; **0.6342** |  0.3245 ; *0.4712* ; *0.6106* |\n",
    "| Support Vector Regression      |   *0.2601*   ; ***0.4451*** ;  *0.6857*  |   0.2570   ; **0.4472** ;   0.6911   |  0.2053 ;  0.4885  ;  0.7183  |\n",
    "| LinearGAM                      |    0.2958    ;    0.4896    ;   0.6526   |  *0.3142*  ;   0.4947   ;   0.6515   |  0.2742 ; *0.4608* ; *0.6160* |\n",
    "| GammaGAM                       |    0.2838    ;    0.4975    ;   0.6637   |   0.2781   ;   0.4929   ;   0.6372   |  |\n",
    "| PoissonGAM                      |   *0.2179*   ;    0.5648    ;  *0.7248*  |   0.1899   ;   0.5833   ;   0.7444   |  0.1784 ; *0.5582* ;  0.7279  |\n",
    "\n",
    "To facilitate the reading and comparaison on the table. The best values per column will be in **bold** and the best values per line will be in *italic*.\n",
    "\n",
    "It appears that the model that performs best is **Extreme Gradient Boosting**. \n",
    "\n",
    "However, no model have good performances. Furthermore, all the models have approximatley the same performance (not much variation in results), exce^t fpr Random Forest who clearly doesn't work with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db70fe",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "From the bivariate analysis we had done in the EDA, we could have predicted this result. Since there are very few correlations in between our features and our target variable, we weren't able to produce a model capable of accurately predicting our target.\n",
    "\n",
    "Perhaps we should have processed our target variable differently, maybe we didn't tranform our features correctly. Currently, except for the fact that we have very few correlations with our target, we don't have another explanation as to why we weren't able to produce a good model for predicting the delay Toronto's bus routes from the weather conditions.\n",
    "\n",
    "However, we did try to do our best to produce a model by doing data collection, extensive analysis on the found data and multiple tests of different models across multiple scenarios. Our conclusion, is not that it is impossible to predict the delays on Toronto's bus routes but rather that we didn't succeed even though we gave it our best effort. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d64afd",
   "metadata": {},
   "source": [
    "## Final notes\n",
    "\n",
    "We did some tests that we didn't documented in this report because we didn't keep the results for different reasons. This section aims to give you an additionnal view on what we did during this project and what we tested.\n",
    "\n",
    "* Tried to optimize models by maximizing/minimizing R²/MAE. The results were very similar to what we acheived with RMSE, in general slighlty worst.\n",
    "* Tried to scale our variable using MinMax scaling. Gave us approximately the same results as standard scaling.\n",
    "* Tried to scale our variable using the Yeo-Johnson transformation. Gave us approximately the same results as standard scaling and MinMax scaling."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
